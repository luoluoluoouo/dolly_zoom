import imageio
import cv2
import numpy as np

from tqdm import tqdm

def center_zoom_distortion(img, strength=0.5):
    h, w = img.shape[:2]
    center_x, center_y = w / 2, h / 2

    # å»ºç«‹æ¯å€‹åƒç´ çš„ (x, y) åº§æ¨™ç¶²æ ¼
    x = np.linspace(0, w - 1, w)
    y = np.linspace(0, h - 1, h)
    xv, yv = np.meshgrid(x, y)

    # è½‰æ›ç‚ºä»¥ä¸­å¿ƒç‚ºåŸé»çš„åº§æ¨™
    dx = (xv - center_x) / center_x
    dy = (yv - center_y) / center_y
    radius = np.sqrt(dx**2 + dy**2)

    # è¨ˆç®—æ”¾å¤§ä¿‚æ•¸ï¼ˆradius è¶Šå°æ”¾å¤§è¶Šå¤šï¼‰
    scale = 1 + strength * (1 - radius)

    # é™åˆ¶æœ€å¤§æ”¾å¤§å€ç‡é¿å…è¶…å‡ºé‚Šç•Œ
    scale = np.clip(scale, 1, 1 + strength)

    # æ˜ å°„å›åŸåœ–åº§æ¨™
    map_x = center_x + dx * center_x / scale
    map_y = center_y + dy * center_y / scale

    # è½‰ç‚º float32 å‹åˆ¥ä»¥ä¾› remap ä½¿ç”¨
    map_x = map_x.astype(np.float32)
    map_y = map_y.astype(np.float32)

    # å¥—ç”¨é‡æ˜ å°„
    distorted = cv2.remap(img, map_x, map_y, interpolation=cv2.INTER_LINEAR)
    return distorted


def center_shrink_distortion(img, strength=0.5):
    h, w = img.shape[:2]
    center_x, center_y = w / 2, h / 2

    # å»ºç«‹æ¯å€‹åƒç´ çš„ (x, y) åº§æ¨™ç¶²æ ¼
    x = np.linspace(0, w - 1, w)
    y = np.linspace(0, h - 1, h)
    xv, yv = np.meshgrid(x, y)

    # è½‰æ›ç‚ºä»¥ä¸­å¿ƒç‚ºåŸé»çš„åº§æ¨™
    dx = (xv - center_x) / center_x
    dy = (yv - center_y) / center_y
    radius = np.sqrt(dx**2 + dy**2)

    # è¨ˆç®—ç¸®å°å€ç‡ï¼ˆradius è¶Šå°ç¸®å°è¶Šå¤šï¼‰
    scale = 1 - strength * (1 - radius)

    # é™åˆ¶æœ€å°ç¸®æ”¾æ¯”ä¾‹é¿å…è®Šå½¢éåº¦ï¼ˆä¾‹å¦‚é¿å… scale è®Šæˆè² å€¼ï¼‰
    scale = np.clip(scale, 1 - strength, 1)

    # æ˜ å°„å›åŸåœ–åº§æ¨™
    map_x = center_x + dx * center_x / scale
    map_y = center_y + dy * center_y / scale

    # è½‰ç‚º float32 å‹åˆ¥ä»¥ä¾› remap ä½¿ç”¨
    map_x = map_x.astype(np.float32)
    map_y = map_y.astype(np.float32)

    # å¥—ç”¨é‡æ˜ å°„
    distorted = cv2.remap(img, map_x, map_y, interpolation=cv2.INTER_LINEAR)
    return distorted


def main(
    left_path: str,
    right_path: str,
    output_gif_path: str = "output.gif",
    fg_strength_range=(0.0, 0.6),
    bg_strength_range=(0.0, 0.3),
    steps=20,
    num_disparities: int = 16 * 5,
    block_size: int = 5,
    min_disparity: int = 0,
    disparity_threshold: int = 20,
    kernel: np.ndarray = np.ones((3, 3), np.uint8),
    invert_mask: bool = False
    ):
    left_bgr = cv2.imread(left_path, cv2.IMREAD_COLOR)
    right_bgr = cv2.imread(right_path, cv2.IMREAD_COLOR)
    if left_bgr is None or right_bgr is None:
        print("âŒ ç„¡æ³•è®€å–å½±åƒï¼Œè«‹ç¢ºèªè·¯å¾‘æ­£ç¢ºã€‚")
        return

    left_gray = cv2.GaussianBlur(cv2.cvtColor(left_bgr, cv2.COLOR_BGR2GRAY), (5, 5), 0)
    right_gray = cv2.GaussianBlur(cv2.cvtColor(right_bgr, cv2.COLOR_BGR2GRAY), (5, 5), 0)

    stereo = cv2.StereoSGBM_create(
        minDisparity=min_disparity,
        numDisparities=num_disparities,
        blockSize=block_size,
        P1=8 * 3 * block_size**2,
        P2=32 * 3 * block_size**2,
        disp12MaxDiff=1,
        uniquenessRatio=10,
        speckleWindowSize=100,
        speckleRange=32
    )
    disparity_raw = stereo.compute(left_gray, right_gray).astype(np.float32) / 16.0
    disparity_raw[disparity_raw < 0] = 0
    disparity_norm = cv2.normalize(disparity_raw, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX).astype(np.uint8)

    mask = disparity_norm > disparity_threshold
    if invert_mask:
        mask = np.logical_not(mask)
    mask_morph = cv2.morphologyEx(mask.astype(np.uint8), cv2.MORPH_CLOSE, kernel, iterations=2)

    frames = []

    fg_strengths = np.concatenate([
        np.linspace(fg_strength_range[0], fg_strength_range[1], steps),
        np.linspace(fg_strength_range[1], fg_strength_range[0], steps)
    ])
    bg_strengths = np.concatenate([
        np.linspace(bg_strength_range[0], bg_strength_range[1], steps),
        np.linspace(bg_strength_range[1], bg_strength_range[0], steps)
    ])

    print("ğŸ“¸ é–‹å§‹ç”¢ç”Ÿå‹•ç•«å¹€...")
    for fg_strength, bg_strength in tqdm(zip(fg_strengths, bg_strengths), total=len(fg_strengths)):
        fg = left_bgr.copy()
        fg[mask_morph == 0] = [0, 0, 0]
        foreground = center_zoom_distortion(fg, strength=fg_strength)
        background = center_shrink_distortion(left_bgr, strength=bg_strength)

        gray_fg = cv2.cvtColor(foreground, cv2.COLOR_BGR2GRAY)
        _, mask_bin = cv2.threshold(gray_fg, 10, 255, cv2.THRESH_BINARY)
        mask_inv = cv2.bitwise_not(mask_bin)

        bg_part = cv2.bitwise_and(background, background, mask=mask_inv)
        fg_part = cv2.bitwise_and(foreground, foreground, mask=mask_bin)
        combined = cv2.add(bg_part, fg_part)

        combined_rgb = cv2.cvtColor(combined, cv2.COLOR_BGR2RGB)
        frames.append(combined_rgb)

    print("ğŸ’¾ å„²å­˜ GIF...")
    imageio.mimsave(output_gif_path, frames, fps=10)
    print(f"âœ… GIF å·²å„²å­˜è‡³ï¼š{output_gif_path}")

if __name__ == "__main__":
    main(
        left_path="images/left.jpg",
        right_path="images/right.jpg",
        output_gif_path="result/dolly_zoom.gif",
        fg_strength_range=(0.0, 0.3),
        bg_strength_range=(0.0, 0.5),
        steps=15,
        num_disparities=16 * 11,
        block_size=11,
        disparity_threshold=35,
        invert_mask=False,
        kernel=np.ones((5, 5), np.uint8)
    )

